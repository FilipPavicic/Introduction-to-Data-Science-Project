{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://archive.ics.uci.edu/ml/datasets/covertype\n",
    "#http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "image_size = 28\n",
    "train_data_count = 60_000\n",
    "test_data_count = 10_000\n",
    "\n",
    "def readGzImages(path,number_of_images):\n",
    "    input_X = gzip.open(path,'r')\n",
    "    input_X.read(16)\n",
    "    buf_X = input_X.read(image_size * image_size * number_of_images)\n",
    "    X = np.frombuffer(buf_X, dtype=np.uint8).astype(np.float32)\n",
    "    X = X.reshape(number_of_images ,image_size * image_size)\n",
    "    return X\n",
    "\n",
    "def readGzLabels(path, number_of_labels):\n",
    "    input_y = gzip.open(path,'r')\n",
    "    input_y.read(8)\n",
    "    buf_y = input_y.read(1 * number_of_labels)\n",
    "    y = np.frombuffer(buf_y, dtype=np.uint8).astype(np.int32)\n",
    "    y = y.reshape(number_of_labels)\n",
    "    return y\n",
    "\n",
    "X = readGzImages('./MNIST_set/train-images-idx3-ubyte.gz', train_data_count)\n",
    "y = readGzLabels('./MNIST_set/train-labels-idx1-ubyte.gz', train_data_count)\n",
    "\n",
    "X_test = readGzImages('./MNIST_set/t10k-images-idx3-ubyte.gz', test_data_count)\n",
    "y_test = readGzLabels('./MNIST_set/t10k-labels-idx1-ubyte.gz', test_data_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_depth_size = [10,15,25]\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(\n",
    "         n_estimators=100, max_features=\"sqrt\", max_depth=tree_depth_size[2],min_samples_split=5\n",
    "         )\n",
    "def indexing(index, size):\n",
    "    arr = np.zeros(size, dtype = np.int8)\n",
    "    arr[index] = 1\n",
    "    return arr\n",
    "\n",
    "clf.fit(X,y)\n",
    "forest = clf.estimators_\n",
    "FI_X = np.array([f.predict(X) for f in forest]).T\n",
    "FI_X_test = np.array([f.predict(X_test) for f in forest]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapToIndexesLeaves1(tree):\n",
    "    mapa = {}\n",
    "    counter = 0\n",
    "    mapa,counter = rekurzivno(tree,mapa,counter,0)\n",
    "    return mapa\n",
    "\n",
    "def rekurzivno(tree, mapa,counter,node):\n",
    "    if tree.children_left[node] == -1:\n",
    "        mapa[node] = counter\n",
    "        counter +=1\n",
    "        return mapa, counter\n",
    "    mapa, counter = rekurzivno(tree, mapa, counter, tree.children_left[node])\n",
    "    mapa, counter = rekurzivno(tree, mapa, counter, tree.children_right[node])\n",
    "    return mapa, counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapToIndexesLeaves(tree):\n",
    "    mapa = {}\n",
    "    counter = 0\n",
    "    for i in range(tree.node_count):\n",
    "        if tree.children_left[i] == -1:\n",
    "            mapa[i] = counter\n",
    "            counter +=1\n",
    "            i = tree.children_right[i-1]\n",
    "    return mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "forestMap = [mapToIndexesLeaves1(f.tree_) for f in forest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3476"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapToIndexesLeaves1(forest[0].tree_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7181\n",
      "[(1271, 1274), (1272, 1273), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]\n"
     ]
    }
   ],
   "source": [
    "print(forest[0].tree_.node_count)\n",
    "forest[65].get_n_leaves()\n",
    "print(list(zip(forest[8].tree_.children_left[1270:1280],forest[8].tree_.children_right[1270:1280])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7195)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[0].decision_path([X[0]]).toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "630"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forestMap[8][1274]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "n_non_leaves = forest[0].tree_.node_count - forest[0].get_n_leaves()\n",
    "indexes = np.subtract(forest[0].apply(X),n_non_leaves)\n",
    "fi = csr_matrix([indexing(i,forest[0].get_n_leaves()) for i in indexes])\n",
    "n_non_leaves1 = forest[1].tree_.node_count - forest[1].get_n_leaves()\n",
    "indexes1 = np.subtract(forest[1].apply(X),n_non_leaves1)\n",
    "fi1 = csr_matrix([indexing(i,forest[1].get_n_leaves()) for i in indexes1])\n",
    "fi2 = hstack([fi,fi1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7429\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "attribute 'children_left' of 'sklearn.tree._tree.Tree' objects is not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-236-705cb18f8c21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mforest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren_left\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: attribute 'children_left' of 'sklearn.tree._tree.Tree' objects is not writable"
     ]
    }
   ],
   "source": [
    "print(len(forest[0].tree_.children_left))\n",
    "forest[0].tree_.children_left = np.delete(forest[0].tree_.children_left,10)\n",
    "print(len(forest[0].tree_.children_left))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7555"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[0].tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 531)\t1\n",
      "  (0, 532)\t1\n",
      "  (0, 533)\t1\n",
      "  (0, 597)\t1\n",
      "  (0, 627)\t1\n",
      "  (0, 628)\t1\n",
      "  (0, 629)\t1\n",
      "  (0, 630)\t1\n",
      "  (0, 640)\t1\n",
      "  (0, 641)\t1\n",
      "  (0, 642)\t1\n",
      "  (0, 643)\t1\n",
      "  (0, 644)\t1\n",
      "  (0, 645)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 4172)\t1\n",
      "  (1, 6938)\t1\n",
      "  (1, 7140)\t1\n",
      "  (1, 7302)\t1\n",
      "  (1, 7303)\t1\n",
      "  (1, 7304)\t1\n",
      "  :\t:\n",
      "  (59998, 7142)\t1\n",
      "  (59998, 7178)\t1\n",
      "  (59998, 7179)\t1\n",
      "  (59998, 7180)\t1\n",
      "  (59998, 7181)\t1\n",
      "  (59998, 7182)\t1\n",
      "  (59998, 7183)\t1\n",
      "  (59998, 7184)\t1\n",
      "  (59998, 7186)\t1\n",
      "  (59998, 7187)\t1\n",
      "  (59998, 7188)\t1\n",
      "  (59999, 0)\t1\n",
      "  (59999, 4172)\t1\n",
      "  (59999, 4173)\t1\n",
      "  (59999, 5385)\t1\n",
      "  (59999, 5865)\t1\n",
      "  (59999, 5866)\t1\n",
      "  (59999, 6214)\t1\n",
      "  (59999, 6215)\t1\n",
      "  (59999, 6216)\t1\n",
      "  (59999, 6260)\t1\n",
      "  (59999, 6286)\t1\n",
      "  (59999, 6287)\t1\n",
      "  (59999, 6288)\t1\n",
      "  (59999, 6289)\t1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(forest[0].decision_path(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leafIndexesOfLeaves(treeDecision,X, offset = 0):\n",
    "    indexes = np.array([])\n",
    "    indices = treeDecision.decision_path(X).indices\n",
    "    tmp = 0\n",
    "    for i in range(len(indices[:-1])):\n",
    "        if indices[i+1] - indices[i] == 1: continue\n",
    "        if indices[i+1] == 0:\n",
    "            indexes = np.append(indexes,tmp + offset)\n",
    "            tmp = 0\n",
    "            continue\n",
    "        tmp = tmp  + (indices[i+1] - indices[i]) // 2\n",
    "    indexes = np.append(indexes,tmp + offset)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leafIndexesOfLeaves1(treeDecision,mapa, X, offset = 0):\n",
    "    return np.array([mapa[x] + offset for x in treeDecision.apply(X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 316., 3675.,  924., ...,  328., 3589., 3141.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leafIndexesOfLeaves(forest[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,f in enumerate(forest):\n",
    "    arr = leafIndexesOfLeaves(f)\n",
    "    if(min(arr) < 0): \n",
    "        print(\"Greška u \"+ i + \"min je: \" + min(arr))\n",
    "    if(max(arr) >= f.get_n_leaves()): \n",
    "        print(\"Greška u \"+ i + \"max je: \" + max(arr) + \", broj listova: \" + f.get_n_leaves())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "def getFI(X, forest):\n",
    "    indptr = np.array([0])\n",
    "    indices = np.array([])\n",
    "    offset = 0\n",
    "    for f in forest:\n",
    "        indexes = leafIndexesOfLeaves(f,X,offset=offset)\n",
    "        indices = np.concatenate((indices,indexes))\n",
    "        offset += f.get_n_leaves()\n",
    "    indptr = np.concatenate((indptr,np.full(60_000,offset)))\n",
    "    FI = csr_matrix((np.ones(indices.shape), indices, indptr), shape=(60_000, np.sum(indptr)))\n",
    "    return FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "def getFI1(X, forest):\n",
    "    col = np.array([])\n",
    "    row = np.array([])\n",
    "    offset = 0\n",
    "    for i,(f,mapa) in enumerate(zip(forest,forestMap)):\n",
    "        indexes = leafIndexesOfLeaves1(f,mapa, X,offset=offset)\n",
    "        col = np.concatenate((col,indexes))\n",
    "        row = np.concatenate((row,np.arange(0,X.shape[0])))\n",
    "        offset += len(mapa)\n",
    "    FI = csr_matrix((np.ones(col.shape,dtype=np.int8), (row, col)), shape=(X.shape[0],offset))\n",
    "    return FI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-91-adfd844deae1>:3: RuntimeWarning: overflow encountered in long_scalars\n",
      "  indptr = np.arange(0,(X.shape[0] + 1) * offset,offset,dtype=np.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "368503"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,(5+1) * 3 ,3)\n",
    "offset\n",
    "indptr = np.arange(0,(X.shape[0] + 1) * offset,offset,dtype=np.float64)\n",
    "indptr[-1]\n",
    "offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI1 = getFI1(X,forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x330464 sparse matrix of type '<class 'numpy.int8'>'\n",
       "\twith 6000000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5176"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = forest[1].apply([X[1]])[0]\n",
    "forestMap[1][a] + forest[0].tree_.n_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI = csr_matrix((np.ones(indices.shape), indices, indptr), shape=(60_000, np.sum(indptr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_test = getFI1(X_test,forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10000x368503 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 368503 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FI_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3278,   197, -3093, ...,  2110,  2786,  1349], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 3598)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368503"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x.get_n_leaves() for x in forest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3597"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[0].tree_.node_count\n",
    "forest[0].get_n_leaves()\n",
    "n_non_leaves = forest[0].tree_.node_count - forest[0].get_n_leaves()\n",
    "n_non_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = forest[0].predict_proba(X)\n",
    "for f in forest[1:]:\n",
    "    a = np.concatenate((a,f.predict_proba(X)),axis =1)\n",
    "\n",
    "a_test = forest[0].predict_proba(X_test)\n",
    "for f in forest[1:]:\n",
    "    a_test = np.concatenate((a_test,f.predict_proba(X_test)),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest[0].predict_proba(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FI_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_X1 = np.array([[indexing(a.astype(int),10) for a in b] for b in FI_X]).reshape(60000,1000)\n",
    "FI_X1_test = np.array([[indexing(a.astype(int),10) for a in b] for b in FI_X_test]).reshape(10000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([indexing(a.astype(int),10) for a in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liblinear.liblinearutil import *\n",
    "y_indexing = np.array([indexing(i,10) for i in y])\n",
    "prob  = problem(y, FI1)\n",
    "param = parameter('-s 2 -c 1 ')\n",
    "m = train(prob, param)\n",
    "[W, b] = m.get_decfun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 97.85% (9785/10000) (classification)\n"
     ]
    }
   ],
   "source": [
    "y_pred,_,_ = predict(y_test, FI_test, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "forest_tmp = copy.deepcopy(forest)\n",
    "forestMap_tmp = copy.deepcopy(forestMap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree._tree import TREE_LEAF\n",
    "neighbors = []\n",
    "offset = 0\n",
    "for i,(mapa,f) in enumerate(zip(forestMap,forest)):\n",
    "    prev_node_index = None\n",
    "    prev_leaf_index = None\n",
    "    for (node_index, leaf_index) in mapa.items():\n",
    "        if prev_node_index is None:\n",
    "            prev_node_index = node_index\n",
    "            prev_leaf_index = leaf_index\n",
    "            continue\n",
    "        \n",
    "        if f.tree_.children_right[prev_node_index - 1] == node_index:\n",
    "            #print(i,prev_node_index,node_index)\n",
    "            singf = abs(W[offset + prev_leaf_index]) + abs (W[offset + leaf_index])\n",
    "            neighbors.append([singf,i,prev_node_index-1])\n",
    "            prev_node_index = None\n",
    "            prev_leaf_index = None\n",
    "            continue\n",
    "        prev_node_index = node_index\n",
    "        prev_leaf_index = leaf_index\n",
    "    offset += len(mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3.5787434916477935e-05, 95, 3801],\n",
       " [5.4814448631998414e-05, 98, 2713],\n",
       " [0.00010112330063747299, 40, 7040],\n",
       " [0.00015286387015271712, 54, 1724],\n",
       " [0.00015356758569464907, 81, 1191],\n",
       " [0.0001984228155173963, 32, 4713],\n",
       " [0.0002034996759221203, 52, 479],\n",
       " [0.0002121913856303953, 56, 5258],\n",
       " [0.00021592820282613883, 91, 6109],\n",
       " [0.0002411791312161632, 61, 6973],\n",
       " [0.000261870819018929, 59, 729],\n",
       " [0.00026434684053572787, 49, 6543],\n",
       " [0.0002764699514984959, 45, 2189],\n",
       " [0.00028886129082041236, 98, 524],\n",
       " [0.00029093549429038383, 50, 1297],\n",
       " [0.0003050386694608301, 61, 5935],\n",
       " [0.0003118802465352752, 53, 2455],\n",
       " [0.0003281782587131175, 96, 7165],\n",
       " [0.0003472477362411722, 40, 1288],\n",
       " [0.00036561291263741206, 67, 4283],\n",
       " [0.0003684495694339031, 67, 1264],\n",
       " [0.0003700452324990657, 54, 6714],\n",
       " [0.0003819694326399446, 68, 1848],\n",
       " [0.0003897844627443133, 32, 4439],\n",
       " [0.0003960551261719433, 73, 6161],\n",
       " [0.0004002734347649724, 34, 979],\n",
       " [0.0004084245644472415, 69, 5992],\n",
       " [0.0004193680319272849, 86, 6919],\n",
       " [0.0004206754098052992, 64, 3943],\n",
       " [0.00042129531792973606, 35, 7110],\n",
       " [0.00042511688148351537, 87, 5139],\n",
       " [0.00042868355916826916, 59, 2612],\n",
       " [0.00043136558373025246, 96, 1872],\n",
       " [0.00043157304269751434, 59, 3391],\n",
       " [0.00045289098962998935, 78, 4644],\n",
       " [0.0004598758294869236, 45, 5091],\n",
       " [0.00046353875190789076, 58, 6832],\n",
       " [0.0004666797885603053, 90, 2365],\n",
       " [0.0004812507120488465, 73, 4934],\n",
       " [0.0005039692797756993, 65, 1644],\n",
       " [0.0005104680433593962, 73, 4354],\n",
       " [0.0005137889504110454, 70, 782],\n",
       " [0.0005178719607122264, 95, 558],\n",
       " [0.0005189975273448312, 95, 7109],\n",
       " [0.0005197327642194073, 41, 6852],\n",
       " [0.0005219369394121774, 54, 6424],\n",
       " [0.0005245605635112443, 35, 7655],\n",
       " [0.0005256518825124809, 74, 2729],\n",
       " [0.0005269290932768797, 42, 4492],\n",
       " [0.0005274904797044861, 32, 7157],\n",
       " [0.0005348377176643796, 37, 4532],\n",
       " [0.0005383046837993133, 98, 1715],\n",
       " [0.0005414809213580404, 44, 5508],\n",
       " [0.0005685704112184625, 56, 2144],\n",
       " [0.0005690865544989307, 91, 2126],\n",
       " [0.0005776178706641411, 55, 6725],\n",
       " [0.0005778403619000151, 99, 285],\n",
       " [0.0005805340172408202, 58, 2880],\n",
       " [0.0005860105795126196, 56, 4808],\n",
       " [0.0005912068688046172, 46, 4885],\n",
       " [0.000591329303683295, 40, 2656],\n",
       " [0.0005944524260331821, 46, 651],\n",
       " [0.000595772228356594, 64, 1796],\n",
       " [0.0006051951499453082, 10, 6917],\n",
       " [0.0006073492983337846, 64, 849],\n",
       " [0.0006222893029266062, 54, 7499],\n",
       " [0.0006236360838922559, 32, 4856],\n",
       " [0.0006243976719242392, 70, 4002],\n",
       " [0.0006274961819761709, 94, 1656],\n",
       " [0.0006316954562047371, 49, 6651],\n",
       " [0.0006398458496950753, 98, 362],\n",
       " [0.0006424853320715549, 95, 3595],\n",
       " [0.000647045746575326, 88, 5715],\n",
       " [0.0006491069712914073, 90, 1018],\n",
       " [0.0006498544963374915, 79, 7555],\n",
       " [0.0006514463147846412, 98, 2868],\n",
       " [0.0006612804256461375, 96, 5985],\n",
       " [0.0006643932653987115, 60, 1731],\n",
       " [0.0006646168299640235, 82, 1483],\n",
       " [0.0006653384849569651, 82, 5273],\n",
       " [0.0006661445937488187, 35, 7114],\n",
       " [0.0006689974063229631, 96, 67],\n",
       " [0.0006757551020367751, 71, 3785],\n",
       " [0.0006766477087801026, 53, 6399],\n",
       " [0.0006897499696905723, 53, 3058],\n",
       " [0.0006955040069581034, 50, 2011],\n",
       " [0.0006973608320087583, 52, 2983],\n",
       " [0.000699527468729958, 82, 3962],\n",
       " [0.0007010018129241324, 65, 3409],\n",
       " [0.0007029276000866032, 44, 6010],\n",
       " [0.0007105437437231006, 95, 6030],\n",
       " [0.0007112016547066525, 99, 4390],\n",
       " [0.0007219920669014285, 46, 1545],\n",
       " [0.0007298205480841116, 60, 793],\n",
       " [0.0007349001194586315, 89, 5094],\n",
       " [0.0007418470762307575, 95, 1669],\n",
       " [0.0007484398222369434, 83, 3544],\n",
       " [0.000749608584417929, 39, 1136],\n",
       " [0.0007504154220145467, 51, 5785],\n",
       " [0.0007568548712514465, 72, 2150],\n",
       " [0.0007595292753742029, 56, 4609],\n",
       " [0.0007756100414465837, 60, 1587],\n",
       " [0.0007842661948274254, 51, 7098],\n",
       " [0.0007885578906612489, 89, 4908],\n",
       " [0.0007891553257108356, 75, 5860],\n",
       " [0.0007893881942050904, 44, 4036],\n",
       " [0.0007906417454937528, 68, 1242],\n",
       " [0.0007912970822342389, 94, 3092],\n",
       " [0.0007922543292926208, 94, 3322],\n",
       " [0.0007930476033594868, 74, 1961],\n",
       " [0.0007954709385567602, 78, 2657],\n",
       " [0.0008009004355036341, 95, 5913],\n",
       " [0.0008027138544501677, 71, 4638],\n",
       " [0.0008105157435364507, 46, 5091],\n",
       " [0.0008188552698524727, 58, 5862],\n",
       " [0.0008211401150099017, 71, 24],\n",
       " [0.0008222220264719658, 95, 2144],\n",
       " [0.0008240501200127844, 78, 3244],\n",
       " [0.0008263948468228536, 34, 5313],\n",
       " [0.0008293220972493251, 37, 4901],\n",
       " [0.0008296213788593384, 95, 2857],\n",
       " [0.0008310102778526153, 42, 4479],\n",
       " [0.0008394585559416153, 40, 3828],\n",
       " [0.0008442258417614221, 32, 4494],\n",
       " [0.0008444582300523605, 78, 5813],\n",
       " [0.0008485959973860207, 80, 5909],\n",
       " [0.0008594292228132262, 93, 5921],\n",
       " [0.0008720838074109462, 90, 1106],\n",
       " [0.0008733391966450038, 41, 142],\n",
       " [0.0008789177447932989, 78, 85],\n",
       " [0.0008790349706752939, 77, 1856],\n",
       " [0.0008794832906572857, 72, 3405],\n",
       " [0.0008825631710598456, 84, 5801],\n",
       " [0.000882927774124574, 96, 4404],\n",
       " [0.0008863016867614835, 57, 77],\n",
       " [0.0008899105366192398, 61, 5835],\n",
       " [0.0008938244747916549, 41, 1319],\n",
       " [0.0008942075636840076, 61, 667],\n",
       " [0.0008971848132443091, 71, 3013],\n",
       " [0.0008996450559138006, 67, 3916],\n",
       " [0.0008999107934346067, 57, 1840],\n",
       " [0.0009023104169511642, 94, 7034],\n",
       " [0.0009077854022912044, 89, 3023],\n",
       " [0.0009111441139139772, 63, 2300],\n",
       " [0.0009135629101354419, 78, 727],\n",
       " [0.0009170925427706493, 42, 4056],\n",
       " [0.0009200408628511824, 45, 3419],\n",
       " [0.0009225894970207465, 90, 4502],\n",
       " [0.0009248575798918761, 68, 215],\n",
       " [0.0009328769460582391, 69, 4529],\n",
       " [0.0009332208463358451, 49, 6234],\n",
       " [0.0009339929801491693, 69, 2221],\n",
       " [0.0009385879612501162, 86, 7152],\n",
       " [0.0009389763200146563, 70, 4353],\n",
       " [0.0009409704248727503, 69, 4844],\n",
       " [0.0009413510089683066, 56, 1232],\n",
       " [0.0009565303480353776, 61, 1637],\n",
       " [0.0009571910635919244, 71, 3020],\n",
       " [0.0009714828729995987, 78, 2543],\n",
       " [0.0009751132366058947, 94, 6708],\n",
       " [0.0009798057103194216, 89, 1296],\n",
       " [0.0009845926316072963, 52, 1387],\n",
       " [0.0009909517612157635, 91, 6104],\n",
       " [0.0009956091470212872, 40, 3707],\n",
       " [0.0009957972321825799, 82, 6414],\n",
       " [0.0009967332370723685, 50, 6806],\n",
       " [0.0009989722740138748, 50, 3977],\n",
       " [0.0009989991220446669, 97, 1767],\n",
       " [0.0010021852217768, 48, 6190],\n",
       " [0.001004053450631019, 88, 911],\n",
       " [0.0010065838328162115, 98, 4985],\n",
       " [0.0010100936100370832, 63, 856],\n",
       " [0.0010138935023059972, 98, 742],\n",
       " [0.0010180570704193819, 33, 424],\n",
       " [0.0010181061395089235, 38, 3841],\n",
       " [0.001018452428465642, 82, 1981],\n",
       " [0.0010196467166753466, 84, 5001],\n",
       " [0.0010207043231832487, 84, 3446],\n",
       " [0.0010252184000606275, 46, 2386],\n",
       " [0.00102628010875323, 84, 653],\n",
       " [0.0010283699252484789, 60, 2341],\n",
       " [0.0010331690051718545, 45, 4141],\n",
       " [0.0010385826101385618, 65, 889],\n",
       " [0.001044797477051334, 95, 1638],\n",
       " [0.0010455048073275512, 65, 3498],\n",
       " [0.0010596738172284062, 88, 5685],\n",
       " [0.0010601945469849309, 89, 2918],\n",
       " [0.0010611945297012634, 36, 5614],\n",
       " [0.0010638104166167503, 78, 7314],\n",
       " [0.001065108324777081, 91, 3104],\n",
       " [0.0010656035878514128, 43, 5695],\n",
       " [0.0010665310586938236, 46, 338],\n",
       " [0.0010669061239989102, 58, 509],\n",
       " [0.0010673084085033595, 71, 6256],\n",
       " [0.001068872139658141, 87, 5725],\n",
       " [0.0010748650274128742, 58, 5890],\n",
       " [0.0010774257024601646, 48, 4375],\n",
       " [0.0010781120949099766, 44, 5485],\n",
       " [0.0010796701691861222, 45, 4378],\n",
       " [0.001080592623761213, 66, 6437],\n",
       " [0.0010816647008720297, 46, 3353],\n",
       " [0.0010817968945065275, 98, 2024],\n",
       " [0.0010825681607725026, 92, 6792],\n",
       " [0.0010844836215506176, 61, 3474],\n",
       " [0.001087898995412662, 60, 3894],\n",
       " [0.0010891150687158428, 56, 3960],\n",
       " [0.001090467904172114, 66, 5287],\n",
       " [0.0010943084910735586, 98, 7219],\n",
       " [0.0010947225189480102, 34, 528],\n",
       " [0.0010975601055316499, 68, 7238],\n",
       " [0.001104098865929527, 50, 429],\n",
       " [0.0011052107616112824, 42, 2174],\n",
       " [0.0011066598246208975, 47, 3727],\n",
       " [0.0011073274241700172, 61, 6115],\n",
       " [0.0011091757858256981, 78, 6483],\n",
       " [0.0011112118917703127, 66, 3552],\n",
       " [0.001120176453371563, 67, 1465],\n",
       " [0.0011226831467938108, 64, 5614],\n",
       " [0.001123160869718904, 43, 5937],\n",
       " [0.0011287949450531848, 89, 2561],\n",
       " [0.0011289579080816037, 87, 835],\n",
       " [0.0011305135668338968, 94, 2492],\n",
       " [0.0011323978087585305, 76, 6144],\n",
       " [0.0011365438572674474, 96, 4122],\n",
       " [0.0011386176912427225, 71, 3727],\n",
       " [0.0011426230224336937, 57, 4688],\n",
       " [0.001142691117450839, 99, 1096],\n",
       " [0.0011428256626054693, 92, 2479],\n",
       " [0.0011431688161299249, 91, 5497],\n",
       " [0.0011488772284160998, 88, 6877],\n",
       " [0.0011491863355109998, 48, 1419],\n",
       " [0.0011496318519716383, 59, 6953],\n",
       " [0.0011569728417273582, 63, 850],\n",
       " [0.0011584104692616611, 73, 6255],\n",
       " [0.001160191831315033, 65, 6263],\n",
       " [0.0011611105666312197, 76, 47],\n",
       " [0.0011635725019199109, 85, 4626],\n",
       " [0.0011641965646488374, 82, 1784],\n",
       " [0.0011644373710302815, 39, 137],\n",
       " [0.0011663629708955035, 73, 891],\n",
       " [0.001170659210766567, 58, 1531],\n",
       " [0.0011712132759084037, 47, 1550],\n",
       " [0.0011727009984580834, 39, 4253],\n",
       " [0.0011750539166734807, 43, 1867],\n",
       " [0.0011758606892010403, 58, 4292],\n",
       " [0.0011789322831889956, 44, 2455],\n",
       " [0.001179692433887056, 71, 1068],\n",
       " [0.0011825022465679412, 90, 5105],\n",
       " [0.00118892426884251, 58, 6407],\n",
       " [0.0011891889784553626, 53, 2685],\n",
       " [0.001196577649613955, 48, 2676],\n",
       " [0.0011987974403426648, 95, 7085],\n",
       " [0.0011988039805248165, 72, 4659],\n",
       " [0.0012011549436371706, 39, 4028],\n",
       " [0.0012024643088449274, 59, 5319],\n",
       " [0.0012059309435293666, 57, 3109],\n",
       " [0.0012087104031046714, 91, 5812],\n",
       " [0.001210481852129148, 76, 4929],\n",
       " [0.0012109789803698714, 70, 4467],\n",
       " [0.001211025638575358, 74, 389],\n",
       " [0.0012120027002311344, 71, 3239],\n",
       " [0.0012122863628469052, 78, 4584],\n",
       " [0.0012133422311288219, 53, 409],\n",
       " [0.0012181365908105353, 82, 3106],\n",
       " [0.0012192976328095132, 79, 2470],\n",
       " [0.0012195987569470304, 96, 7092],\n",
       " [0.0012257801219783715, 40, 891],\n",
       " [0.0012261607099857815, 50, 3260],\n",
       " [0.0012269749026663362, 79, 2413],\n",
       " [0.0012294155822133613, 64, 2732],\n",
       " [0.001229822957620222, 86, 843],\n",
       " [0.0012306808312839237, 35, 1749],\n",
       " [0.0012313772157391074, 53, 869],\n",
       " [0.0012318730273731036, 33, 2151],\n",
       " [0.0012425535308924198, 86, 7063],\n",
       " [0.0012436499744197275, 52, 5649],\n",
       " [0.0012503358211033435, 21, 3755],\n",
       " [0.0012539118682045939, 44, 6304],\n",
       " [0.0012565321369955508, 55, 1922],\n",
       " [0.0012576219368586371, 59, 496],\n",
       " [0.0012587670311825223, 45, 6462],\n",
       " [0.0012595612348743877, 48, 1375],\n",
       " [0.0012606640227826454, 42, 3709],\n",
       " [0.0012636188170822176, 52, 4158],\n",
       " [0.0012639638375737893, 59, 6151],\n",
       " [0.001267621696904072, 60, 262],\n",
       " [0.0012711643843961477, 37, 2258],\n",
       " [0.0012732297707215901, 41, 1659],\n",
       " [0.0012790311553511772, 58, 7090],\n",
       " [0.0012858432241290442, 63, 5503],\n",
       " [0.0012866876722148505, 88, 1941],\n",
       " [0.0012883412639000157, 39, 4019],\n",
       " [0.0012884182033632001, 60, 5866],\n",
       " [0.0012899749400180622, 33, 1661],\n",
       " [0.0012909773465264035, 60, 312],\n",
       " [0.0012910284719614346, 82, 1746],\n",
       " [0.001297347019392583, 73, 1367],\n",
       " [0.0012988066443749336, 35, 6224],\n",
       " [0.00130270994802373, 84, 6573],\n",
       " [0.0013048613679360194, 36, 4332],\n",
       " [0.0013049792587359948, 46, 552],\n",
       " [0.0013103259044508632, 50, 5615],\n",
       " [0.0013140228864191791, 50, 7279],\n",
       " [0.0013148867906790204, 81, 6345],\n",
       " [0.0013173804518423066, 86, 4051],\n",
       " [0.0013196278539061666, 62, 1309],\n",
       " [0.0013196426767563656, 73, 191],\n",
       " [0.0013232611750793246, 57, 4509],\n",
       " [0.001323392826681804, 69, 1270],\n",
       " [0.0013240108768749047, 33, 5387],\n",
       " [0.0013264147965398954, 32, 1582],\n",
       " [0.0013275889271520012, 56, 100],\n",
       " [0.0013290479393829597, 72, 1613],\n",
       " [0.0013358754291537323, 82, 6280],\n",
       " [0.0013371827809954373, 71, 495],\n",
       " [0.0013394888479908466, 48, 6399],\n",
       " [0.001341373138814122, 64, 4782],\n",
       " [0.0013439031352540176, 57, 1658],\n",
       " [0.0013460887918302215, 90, 5072],\n",
       " [0.0013500098565695788, 92, 3662],\n",
       " [0.0013520216392542026, 95, 2963],\n",
       " [0.00135558881343322, 47, 4185],\n",
       " [0.0013570238027737912, 83, 2777],\n",
       " [0.0013614224526349425, 56, 5693],\n",
       " [0.0013635522438927197, 74, 740],\n",
       " [0.0013665749466932348, 51, 4278],\n",
       " [0.0013682964678706881, 98, 2596],\n",
       " [0.0013696628430346087, 95, 450],\n",
       " [0.0013711804332342784, 96, 873],\n",
       " [0.0013732782623251082, 57, 4140],\n",
       " [0.0013735491464173571, 38, 984],\n",
       " [0.0013761973370682086, 58, 3140],\n",
       " [0.00137964644356837, 82, 6998],\n",
       " [0.0013802283892815452, 86, 296],\n",
       " [0.0013805718850261664, 82, 1656],\n",
       " [0.0013810883988857527, 86, 5588],\n",
       " [0.0013822106966860574, 88, 3393],\n",
       " [0.0013859984342445306, 98, 2406],\n",
       " [0.001388955311073204, 55, 5475],\n",
       " [0.00138971235129634, 83, 316],\n",
       " [0.0013903818351199697, 51, 4699],\n",
       " [0.0013907588489054236, 39, 1257],\n",
       " [0.0013942838357502896, 97, 4603],\n",
       " [0.0013946142994748561, 86, 1017],\n",
       " [0.0013980803242904286, 95, 3096],\n",
       " [0.001398892201132423, 76, 5831],\n",
       " [0.0013989678476440967, 66, 2092],\n",
       " [0.001399805573783389, 97, 4320],\n",
       " [0.001403730062685001, 44, 2700],\n",
       " [0.001404980013336589, 92, 2360],\n",
       " [0.0014057430751800068, 92, 6846],\n",
       " [0.0014150100810218533, 34, 853],\n",
       " [0.0014171239958387948, 99, 6554],\n",
       " [0.0014178859193063316, 72, 762],\n",
       " [0.0014181958785192646, 90, 6744],\n",
       " [0.0014221385575042451, 98, 225],\n",
       " [0.0014253451222090209, 77, 7026],\n",
       " [0.0014254994297269647, 82, 4277],\n",
       " [0.0014263588570175582, 34, 234],\n",
       " [0.0014290895223353335, 56, 3493],\n",
       " [0.0014315480112006697, 72, 1755],\n",
       " [0.0014328366672567803, 53, 1795],\n",
       " [0.0014353133167423087, 75, 6544],\n",
       " [0.0014385319802395174, 54, 6388],\n",
       " [0.0014410540489529246, 84, 556],\n",
       " [0.0014423964374999606, 74, 3630],\n",
       " [0.0014430332032329069, 68, 2512],\n",
       " [0.0014434105553945398, 22, 1339],\n",
       " [0.0014437070199601865, 82, 1778],\n",
       " [0.0014472091757357836, 51, 3983],\n",
       " [0.001447781626098493, 62, 2232],\n",
       " [0.001449651935845568, 42, 4649],\n",
       " [0.0014516552804138593, 93, 5780],\n",
       " [0.0014517950421596816, 34, 5140],\n",
       " [0.0014538810405716053, 76, 2766],\n",
       " [0.0014555200567320703, 92, 2900],\n",
       " [0.0014569785292518748, 68, 2269],\n",
       " [0.0014592516159456221, 47, 2830],\n",
       " [0.0014613278083439474, 61, 6522],\n",
       " [0.0014625601187503836, 71, 4873],\n",
       " [0.0014626400069456316, 83, 3459],\n",
       " [0.001463552517946158, 94, 2194],\n",
       " [0.001464564164458307, 62, 736],\n",
       " [0.0014650902401661383, 74, 6626],\n",
       " [0.0014658672782158647, 88, 2185],\n",
       " [0.0014659251071252413, 85, 6723],\n",
       " [0.0014670336318528942, 61, 3519],\n",
       " [0.001467090555964573, 45, 4334],\n",
       " [0.0014693364889854096, 69, 3468],\n",
       " [0.001471524510186199, 68, 6519],\n",
       " [0.001474873427338218, 94, 5856],\n",
       " [0.001476494609299652, 64, 3998],\n",
       " [0.0014771032860250112, 65, 2790],\n",
       " [0.0014781056013611102, 64, 5423],\n",
       " [0.0014807600904942469, 93, 4666],\n",
       " [0.0014812962245265356, 41, 4007],\n",
       " [0.001482237221487353, 32, 5005],\n",
       " [0.0014828619082756585, 37, 6584],\n",
       " [0.0014842678603101827, 51, 2750],\n",
       " [0.0014844092280851397, 72, 3154],\n",
       " [0.0014845869739807311, 37, 2530],\n",
       " [0.001484705317824579, 84, 6613],\n",
       " [0.001484764940276602, 87, 5050],\n",
       " [0.001486669200410048, 91, 2430],\n",
       " [0.0014896301249050017, 14, 4027],\n",
       " [0.0014920435119361735, 79, 1724],\n",
       " [0.0014928741791710924, 56, 1583],\n",
       " [0.00149340588019411, 71, 1851],\n",
       " [0.0014942971839480878, 75, 4948],\n",
       " [0.001496696739460597, 64, 7233],\n",
       " [0.0014991129644195268, 47, 4257],\n",
       " [0.0015000676103988663, 97, 1100],\n",
       " [0.0015046789116468574, 59, 385],\n",
       " [0.0015058229671618697, 56, 7020],\n",
       " [0.0015061089977132865, 83, 5600],\n",
       " [0.0015067672525515391, 95, 5958],\n",
       " [0.0015076410982635033, 56, 2052],\n",
       " [0.0015084212558031888, 53, 3358],\n",
       " [0.0015095305382712703, 96, 1379],\n",
       " [0.0015103229911706919, 72, 6126],\n",
       " [0.001510869037073309, 61, 5845],\n",
       " [0.0015121182734709289, 64, 7316],\n",
       " [0.0015137323997752943, 98, 5171],\n",
       " [0.0015142443620957291, 92, 128],\n",
       " [0.0015145114071027578, 55, 5415],\n",
       " [0.001514674262506705, 40, 3989],\n",
       " [0.0015157797545412377, 66, 1375],\n",
       " [0.0015165552211498154, 91, 238],\n",
       " [0.0015166228577133834, 76, 6747],\n",
       " [0.0015188644553700006, 88, 4861],\n",
       " [0.0015199634902036273, 78, 5272],\n",
       " [0.0015202216446377798, 69, 1698],\n",
       " [0.0015204632224620307, 90, 5787],\n",
       " [0.0015215459102299687, 87, 5943],\n",
       " [0.0015220805459242195, 42, 3917],\n",
       " [0.001522787558217499, 43, 655],\n",
       " [0.001527839121399351, 61, 3501],\n",
       " [0.0015287291575779266, 58, 6170],\n",
       " [0.0015303011078325627, 81, 4818],\n",
       " [0.0015326229889307892, 79, 6711],\n",
       " [0.0015327212814388593, 93, 1783],\n",
       " [0.0015333923642724709, 60, 1056],\n",
       " [0.0015339328982636221, 39, 5488],\n",
       " [0.0015391049830839258, 33, 5334],\n",
       " [0.0015392138160970211, 42, 4563],\n",
       " [0.0015399031466114084, 73, 3354],\n",
       " [0.0015404341126167005, 92, 5414],\n",
       " [0.001542402479922232, 81, 2475],\n",
       " [0.0015471368294949334, 62, 2656],\n",
       " [0.0015488950810245553, 40, 4472],\n",
       " [0.0015489802192838625, 52, 5828],\n",
       " [0.0015557541106077182, 30, 6936],\n",
       " [0.0015563655575277094, 89, 4134],\n",
       " [0.0015564370961026655, 92, 531],\n",
       " [0.0015568608122555375, 75, 5340],\n",
       " [0.0015590223671285268, 81, 7031],\n",
       " [0.0015630799821403584, 89, 6967],\n",
       " [0.0015642692570045462, 66, 6218],\n",
       " [0.0015647774497559996, 49, 5509],\n",
       " [0.0015653983982798255, 38, 2304],\n",
       " [0.0015659789788864276, 92, 5261],\n",
       " [0.001568723649309847, 78, 3645],\n",
       " [0.001568816099534841, 81, 2558],\n",
       " [0.0015697597656652133, 37, 2330],\n",
       " [0.0015707406866147093, 97, 1424],\n",
       " [0.001576528150941476, 60, 814],\n",
       " [0.001579467649771491, 84, 3059],\n",
       " [0.0015795463809158607, 84, 1216],\n",
       " [0.0015821060259787096, 76, 6549],\n",
       " [0.0015829527307802127, 86, 4543],\n",
       " [0.0015850548542556786, 40, 4084],\n",
       " [0.0015861783483984376, 94, 2935],\n",
       " [0.0015868843451384514, 38, 4048],\n",
       " [0.0015887529960230981, 79, 6999],\n",
       " [0.001590102009150438, 66, 4485],\n",
       " [0.0015911565648374624, 98, 6761],\n",
       " [0.0015919904260230772, 71, 4292],\n",
       " [0.0015926858806576464, 34, 963],\n",
       " [0.0015929012652913797, 71, 6353],\n",
       " [0.001593556954136367, 67, 6095],\n",
       " [0.0015970018068113565, 98, 4755],\n",
       " [0.0015997202264165268, 35, 5650],\n",
       " [0.001600976001705133, 54, 2619],\n",
       " [0.0016011137129384725, 63, 243],\n",
       " [0.0016074366982994045, 65, 6789],\n",
       " [0.001608598759498268, 50, 835],\n",
       " [0.0016089397596853084, 63, 6870],\n",
       " [0.0016130127179437377, 85, 2691],\n",
       " [0.001614088420711233, 41, 2069],\n",
       " [0.0016167049374974964, 69, 3934],\n",
       " [0.0016207376554556129, 55, 5095],\n",
       " [0.0016254767940807556, 33, 2905],\n",
       " [0.0016254912619453267, 70, 4250],\n",
       " [0.0016271629087173472, 66, 4104],\n",
       " [0.001627736910784098, 41, 3425],\n",
       " [0.001630091677552866, 43, 4101],\n",
       " [0.0016339345590030644, 94, 1088],\n",
       " [0.001635575491443122, 46, 5614],\n",
       " [0.001638363883213635, 40, 1320],\n",
       " [0.0016387028757949952, 82, 5164],\n",
       " [0.0016392387319001443, 92, 3967],\n",
       " [0.0016405196166430517, 32, 3755],\n",
       " [0.001642125270155002, 87, 2071],\n",
       " [0.001647388284030962, 81, 6055],\n",
       " [0.0016537931584535066, 58, 1252],\n",
       " [0.0016573461091499689, 54, 3301],\n",
       " [0.0016585670087537153, 72, 6284],\n",
       " [0.0016586258754398408, 76, 6827],\n",
       " [0.0016589682424007258, 83, 5368],\n",
       " [0.0016589995704795134, 37, 3880],\n",
       " [0.0016594910733302333, 86, 2216],\n",
       " [0.0016595165637700764, 79, 2033],\n",
       " [0.0016650496991642914, 59, 2702],\n",
       " [0.0016657912434019173, 54, 6753],\n",
       " [0.0016672571231954808, 57, 744],\n",
       " [0.0016715835908518413, 87, 4799],\n",
       " [0.001675304851126476, 88, 4973],\n",
       " [0.0016776264388079437, 59, 4602],\n",
       " [0.0016783693493653455, 94, 6317],\n",
       " [0.0016809443627999858, 47, 6305],\n",
       " [0.001681784916905788, 88, 2577],\n",
       " [0.0016820370009932237, 70, 1183],\n",
       " [0.0016825774706897426, 68, 446],\n",
       " [0.0016828808463416139, 72, 3506],\n",
       " [0.0016848310980415947, 64, 1917],\n",
       " [0.0016897290984292667, 73, 4611],\n",
       " [0.001691918845366923, 66, 4023],\n",
       " [0.0016933846083319747, 98, 1889],\n",
       " [0.0016935621523653736, 44, 4009],\n",
       " [0.0016999350331474289, 61, 5020],\n",
       " [0.0017019106593802787, 73, 5441],\n",
       " [0.0017031572890012058, 70, 1808],\n",
       " [0.0017032856110969427, 93, 1355],\n",
       " [0.001711142404173902, 40, 1504],\n",
       " [0.0017131979488501773, 72, 3891],\n",
       " [0.0017140408782323428, 98, 3366],\n",
       " [0.0017184292578508425, 69, 3135],\n",
       " [0.0017202091886998675, 51, 7119],\n",
       " [0.001720944599810328, 36, 5220],\n",
       " [0.0017253363322341526, 63, 4780],\n",
       " [0.0017270870197010756, 79, 2086],\n",
       " [0.0017281402302335444, 63, 3608],\n",
       " [0.0017295136415888634, 45, 1557],\n",
       " [0.0017297804161047316, 71, 5393],\n",
       " [0.0017336412166979334, 90, 1580],\n",
       " [0.0017339760324410836, 70, 4967],\n",
       " [0.0017348142683011485, 51, 5203],\n",
       " [0.0017348317685753373, 78, 5277],\n",
       " [0.0017352903431497456, 58, 4898],\n",
       " [0.001736706845434482, 86, 2889],\n",
       " [0.0017368933411136048, 71, 6647],\n",
       " [0.001737573176199859, 59, 835],\n",
       " [0.001737588283607636, 74, 698],\n",
       " [0.0017393662396831657, 47, 3795],\n",
       " [0.0017400730740966884, 53, 4400],\n",
       " [0.0017413181193974853, 65, 950],\n",
       " [0.001744128295476319, 35, 2802],\n",
       " [0.0017443337917258848, 36, 1816],\n",
       " [0.0017456812856301086, 59, 3573],\n",
       " [0.0017514979896830019, 64, 6047],\n",
       " [0.001752152942589492, 32, 2203],\n",
       " [0.0017525047230334363, 94, 2482],\n",
       " [0.0017556539758618193, 40, 4352],\n",
       " [0.001756345506623352, 55, 1697],\n",
       " [0.0017573699276818386, 99, 5564],\n",
       " [0.001757462479294362, 75, 5596],\n",
       " [0.0017581036294136729, 90, 6686],\n",
       " [0.0017600505006252992, 71, 3310],\n",
       " [0.0017602491006858732, 74, 5518],\n",
       " [0.0017603423606820426, 69, 7381],\n",
       " [0.0017609779324263722, 70, 5721],\n",
       " [0.0017615575064845955, 95, 1862],\n",
       " [0.0017616465834139556, 80, 6868],\n",
       " [0.001762939308572009, 97, 5714],\n",
       " [0.001763740334011949, 62, 2003],\n",
       " [0.0017644148672826846, 36, 3703],\n",
       " [0.0017645664591465215, 55, 5232],\n",
       " [0.001767371804601219, 83, 5635],\n",
       " [0.0017674669030981708, 98, 2006],\n",
       " [0.001771690737631126, 47, 3609],\n",
       " [0.0017725255012284494, 53, 7338],\n",
       " [0.0017731728736256596, 72, 6489],\n",
       " [0.0017758490781637718, 82, 7114],\n",
       " [0.0017783611822225214, 76, 2590],\n",
       " [0.001781185616842012, 56, 5072],\n",
       " [0.0017812729327769759, 66, 6774],\n",
       " [0.001783537261252524, 64, 4383],\n",
       " [0.0017857297733028916, 54, 4393],\n",
       " [0.0017857360137414494, 74, 1614],\n",
       " [0.001788580412696292, 78, 4494],\n",
       " [0.0017888547554498445, 46, 1274],\n",
       " [0.0017898939269676477, 56, 7424],\n",
       " [0.0017911090370225633, 42, 3119],\n",
       " [0.0017930927078907515, 67, 4573],\n",
       " [0.0017981123928731552, 53, 3197],\n",
       " [0.0017986151959307993, 64, 6430],\n",
       " [0.0018002161246873042, 29, 2682],\n",
       " [0.0018010829339089305, 36, 1889],\n",
       " [0.0018019895946308853, 86, 5805],\n",
       " [0.0018020041183323054, 80, 4272],\n",
       " [0.0018028140251189926, 54, 3371],\n",
       " [0.0018053243809271814, 42, 558],\n",
       " [0.0018070371473824886, 59, 6533],\n",
       " [0.0018071233988445315, 66, 6860],\n",
       " [0.0018075630890368227, 81, 1055],\n",
       " [0.0018086283202616187, 40, 410],\n",
       " [0.0018091316243304262, 44, 6275],\n",
       " [0.0018171559017028439, 92, 2137],\n",
       " [0.001817472497364324, 99, 5386],\n",
       " [0.00181776131541933, 71, 6728],\n",
       " [0.0018198991963602532, 80, 3480],\n",
       " [0.0018225934563760576, 85, 4372],\n",
       " [0.001823453102111026, 48, 1024],\n",
       " [0.0018237974462072884, 41, 1600],\n",
       " [0.0018238759498830442, 80, 7399],\n",
       " [0.0018240043614952725, 71, 6271],\n",
       " [0.0018247757896265523, 90, 5120],\n",
       " [0.001824936476684421, 45, 2686],\n",
       " [0.0018268923627689098, 70, 5943],\n",
       " [0.001829021968728607, 33, 365],\n",
       " [0.001829503950374261, 47, 4776],\n",
       " [0.001830336354948656, 71, 5403],\n",
       " [0.0018323261768201135, 43, 3373],\n",
       " [0.0018350148712822966, 54, 6823],\n",
       " [0.0018353558504696527, 46, 1625],\n",
       " [0.0018353602303502943, 71, 4566],\n",
       " [0.001839489268652723, 43, 377],\n",
       " [0.0018418577581304635, 56, 739],\n",
       " [0.001845847195044518, 84, 2667],\n",
       " [0.0018484888801128107, 92, 75],\n",
       " [0.001850320269537752, 73, 2547],\n",
       " [0.0018504869306155156, 85, 5637],\n",
       " [0.001853612159197271, 41, 2643],\n",
       " [0.0018552525060768887, 62, 5616],\n",
       " [0.0018553255042669159, 63, 724],\n",
       " [0.001857469543417199, 97, 4117],\n",
       " [0.0018588447868750453, 35, 5532],\n",
       " [0.0018603382202896197, 84, 1181],\n",
       " [0.001860700913844334, 80, 5893],\n",
       " [0.0018608764492337795, 85, 5983],\n",
       " [0.001860992232591312, 98, 5202],\n",
       " [0.001863108944424785, 79, 3412],\n",
       " [0.0018632073679567028, 60, 2587],\n",
       " [0.001864932196795086, 48, 3116],\n",
       " [0.001865177825356342, 92, 5539],\n",
       " [0.0018660616573193051, 48, 6954],\n",
       " [0.0018668241336405281, 58, 4525],\n",
       " [0.0018686900914124834, 60, 1102],\n",
       " [0.0018695207464244526, 81, 2189],\n",
       " [0.0018695317571641812, 38, 3991],\n",
       " [0.001869687911198641, 89, 4895],\n",
       " [0.0018708685003342648, 55, 215],\n",
       " [0.001872166820987525, 67, 5479],\n",
       " [0.001873375656338508, 73, 5236],\n",
       " [0.0018739984940690673, 68, 2559],\n",
       " [0.0018785866639267081, 63, 684],\n",
       " [0.0018813725267518245, 43, 4729],\n",
       " [0.001881866428533028, 37, 3197],\n",
       " [0.0018819289917486677, 63, 1543],\n",
       " [0.0018821039146917063, 61, 2866],\n",
       " [0.0018831299157152496, 69, 3021],\n",
       " [0.0018833826537659303, 71, 2367],\n",
       " [0.0018844350105648726, 60, 3611],\n",
       " [0.0018850369503418864, 64, 4181],\n",
       " [0.001885090335846073, 59, 4346],\n",
       " [0.0018854865227135164, 78, 6746],\n",
       " [0.0018863178263176014, 55, 7160],\n",
       " [0.0018864237265606638, 76, 5781],\n",
       " [0.0018904742338741835, 52, 7271],\n",
       " [0.0018910979283955106, 48, 1580],\n",
       " [0.0018938653785065408, 78, 1346],\n",
       " [0.0018941811710852558, 88, 6605],\n",
       " [0.001895840711714298, 92, 6377],\n",
       " [0.0018963890277962053, 92, 3912],\n",
       " [0.001896954463247779, 63, 4554],\n",
       " [0.0018981692868600022, 60, 7210],\n",
       " [0.0018991688720359427, 80, 3531],\n",
       " [0.0019004343585028042, 91, 5209],\n",
       " [0.0019011752562925837, 94, 3596],\n",
       " [0.0019030129272809002, 89, 5514],\n",
       " [0.0019031558640830182, 48, 4842],\n",
       " [0.0019068970574241, 90, 3990],\n",
       " [0.0019093228646671222, 79, 6030],\n",
       " [0.0019100175952962918, 95, 3573],\n",
       " [0.0019111652549091847, 49, 2054],\n",
       " [0.001913016643968563, 83, 1262],\n",
       " [0.0019130736172332423, 71, 491],\n",
       " [0.0019144578221343877, 33, 2250],\n",
       " [0.0019179730612670363, 72, 5681],\n",
       " [0.0019184686894118572, 34, 4287],\n",
       " [0.0019277829352594654, 80, 4807],\n",
       " [0.001928095170643674, 54, 2797],\n",
       " [0.0019281703578619019, 43, 359],\n",
       " [0.0019293763771627405, 64, 731],\n",
       " [0.0019307536822518207, 98, 5041],\n",
       " [0.001931035179411247, 41, 5421],\n",
       " [0.0019310855470080334, 62, 2848],\n",
       " [0.0019323750022016552, 55, 4177],\n",
       " [0.0019345989791198256, 58, 3448],\n",
       " [0.0019347210873555242, 73, 4735],\n",
       " [0.0019349378399342253, 77, 1842],\n",
       " [0.0019363187811228429, 33, 1280],\n",
       " [0.0019375910694073737, 62, 2029],\n",
       " [0.0019399716166760982, 78, 3212],\n",
       " [0.0019400303818752616, 59, 1636],\n",
       " [0.001940683227532142, 41, 7223],\n",
       " [0.0019414816842941362, 62, 2870],\n",
       " [0.001944762717465185, 83, 4960],\n",
       " [0.0019448608323811077, 39, 4992],\n",
       " [0.0019457502889355367, 82, 1137],\n",
       " [0.0019476790874997014, 44, 6899],\n",
       " [0.0019484619239106308, 59, 6728],\n",
       " [0.0019501205652901336, 54, 4728],\n",
       " [0.0019502252782895592, 56, 4505],\n",
       " [0.001950344606286253, 84, 2796],\n",
       " [0.001954813908780191, 67, 6505],\n",
       " [0.0019556721606799944, 84, 6662],\n",
       " [0.001958638133522772, 85, 5352],\n",
       " [0.0019589945268191594, 66, 1618],\n",
       " [0.0019618450484010694, 46, 3470],\n",
       " [0.001964195958045186, 57, 7176],\n",
       " [0.0019643315783450387, 73, 6269],\n",
       " [0.0019650435027872473, 99, 3380],\n",
       " [0.0019690235352820304, 71, 4391],\n",
       " [0.001969562446706396, 52, 2216],\n",
       " [0.0019709487300432534, 70, 1462],\n",
       " [0.0019735649021735847, 85, 4792],\n",
       " [0.0019769258065335396, 85, 5844],\n",
       " [0.0019774900437623554, 49, 1901],\n",
       " [0.0019788615711240367, 35, 1738],\n",
       " [0.001985774383063442, 58, 2761],\n",
       " [0.001986170956511763, 56, 5187],\n",
       " [0.001988442383467943, 56, 1398],\n",
       " [0.0019894443401672385, 62, 6270],\n",
       " [0.0019901305104007526, 34, 2850],\n",
       " [0.0019907291261361364, 72, 4058],\n",
       " [0.0019909078844449583, 79, 4743],\n",
       " [0.0019920942438764132, 96, 5945],\n",
       " [0.0019925591230122598, 61, 1173],\n",
       " [0.0019939741069831454, 32, 3418],\n",
       " [0.001994250473855685, 78, 5969],\n",
       " [0.001994870580607164, 40, 3330],\n",
       " [0.001998037040714365, 99, 1535],\n",
       " [0.0019989528622477238, 70, 1299],\n",
       " [0.002001498039351708, 59, 1243],\n",
       " [0.0020020834126983833, 51, 7023],\n",
       " [0.002003843364108737, 49, 4982],\n",
       " [0.002003851477633826, 73, 3006],\n",
       " [0.0020044921716426503, 46, 3035],\n",
       " [0.00200582401027236, 83, 5454],\n",
       " [0.002006259039524866, 91, 5193],\n",
       " [0.0020063962458035356, 48, 1399],\n",
       " [0.002007135841397131, 95, 707],\n",
       " [0.0020072496173792736, 76, 2402],\n",
       " [0.002008060063119956, 62, 2945],\n",
       " [0.0020096403258577514, 99, 3479],\n",
       " [0.002010488653405694, 70, 6879],\n",
       " [0.002013865434315026, 94, 6758],\n",
       " [0.00201387546698321, 65, 4192],\n",
       " [0.0020146280040490355, 37, 323],\n",
       " [0.0020180974848078796, 51, 3281],\n",
       " [0.0020185502726344806, 70, 4519],\n",
       " [0.002018802377556188, 66, 1885],\n",
       " [0.002019973095120851, 39, 224],\n",
       " [0.002021117856075781, 43, 85],\n",
       " [0.002022057670908024, 41, 1838],\n",
       " [0.002023787210491024, 64, 5271],\n",
       " [0.002023842414218557, 82, 7148],\n",
       " [0.0020277406800695633, 43, 4308],\n",
       " [0.0020298588355343256, 98, 5251],\n",
       " [0.0020341008888834057, 91, 3944],\n",
       " [0.002035809198966624, 68, 3941],\n",
       " [0.002037118592441487, 83, 6967],\n",
       " [0.0020383513951582723, 67, 1564],\n",
       " [0.0020392378986691124, 86, 7115],\n",
       " [0.002039627196413809, 37, 6414],\n",
       " [0.0020397211465436648, 83, 1402],\n",
       " [0.0020407808770721704, 71, 538],\n",
       " [0.002041194455283473, 65, 1291],\n",
       " [0.0020422145865044423, 75, 1475],\n",
       " [0.0020443973771644267, 39, 674],\n",
       " [0.002045769676930244, 68, 5488],\n",
       " [0.002047714809968391, 90, 1023],\n",
       " [0.0020481902864638293, 95, 7055],\n",
       " [0.0020491795744481066, 71, 280],\n",
       " [0.0020497831833758895, 73, 6381],\n",
       " [0.0020518017166604114, 38, 5923],\n",
       " [0.0020528938986479764, 54, 1870],\n",
       " [0.0020543744402160913, 91, 1817],\n",
       " [0.002054741475340153, 45, 5924],\n",
       " [0.0020557410901705583, 76, 3256],\n",
       " [0.0020569030884689675, 40, 3847],\n",
       " [0.002058037592365835, 33, 2355],\n",
       " [0.0020609417781442723, 63, 1570],\n",
       " [0.0020614438801778564, 88, 2356],\n",
       " [0.002062242726422415, 53, 2836],\n",
       " [0.0020624669859891404, 58, 6953],\n",
       " [0.002062707097978722, 60, 2376],\n",
       " [0.00206281207350858, 69, 3844],\n",
       " [0.0020647845900567223, 59, 3597],\n",
       " [0.0020650890211569295, 85, 5092],\n",
       " [0.002067323542998493, 79, 1741],\n",
       " [0.002068021296053952, 95, 1118],\n",
       " [0.002068115435518996, 38, 4974],\n",
       " [0.002068388483737609, 53, 601],\n",
       " [0.0020695839645572113, 39, 5465],\n",
       " [0.0020696461016052156, 82, 6512],\n",
       " [0.002069654901784853, 36, 3419],\n",
       " [0.0020718448911274845, 84, 400],\n",
       " [0.0020723375170960245, 77, 7122],\n",
       " [0.0020726668891532115, 84, 5455],\n",
       " [0.0020730596215372656, 72, 4318],\n",
       " [0.0020740602539550718, 49, 5340],\n",
       " [0.002074547824409775, 80, 6337],\n",
       " [0.0020761568409526964, 77, 4828],\n",
       " [0.002076550063529472, 79, 5533],\n",
       " [0.002079401766009411, 73, 846],\n",
       " [0.0020813744577480656, 89, 3144],\n",
       " [0.0020816263004502953, 70, 588],\n",
       " [0.002082542969203193, 83, 7523],\n",
       " [0.0020837936249057587, 69, 453],\n",
       " [0.0020843552451199135, 57, 5859],\n",
       " [0.0020854619092748, 89, 1047],\n",
       " [0.0020859683743842715, 55, 3428],\n",
       " [0.002089796649440933, 73, 1062],\n",
       " [0.0020914810763963, 91, 2076],\n",
       " [0.0020916103555591384, 83, 4094],\n",
       " [0.0020917059768179964, 56, 4513],\n",
       " [0.0020926853105483517, 53, 5849],\n",
       " [0.0020931397281899917, 42, 6800],\n",
       " [0.0020935568266858004, 85, 554],\n",
       " [0.002094491924258531, 79, 6044],\n",
       " [0.0020953508043381652, 76, 6588],\n",
       " [0.0020960759980202565, 79, 4070],\n",
       " [0.0020962249565751163, 55, 4744],\n",
       " [0.0020963163662089234, 34, 1523],\n",
       " [0.002098460592698927, 61, 612],\n",
       " [0.0020988676333183296, 39, 2959],\n",
       " [0.0021000691981437137, 44, 1622],\n",
       " [0.0021004068380298816, 87, 7010],\n",
       " [0.0021008402765852843, 86, 2650],\n",
       " [0.0021009919215841085, 37, 3867],\n",
       " [0.0021011897599371126, 90, 4531],\n",
       " [0.0021025173477682165, 47, 4402],\n",
       " [0.002102551427102161, 89, 1144],\n",
       " [0.002103443878612284, 90, 3527],\n",
       " [0.00210356984382654, 51, 4731],\n",
       " [0.002103593471046612, 98, 5450],\n",
       " [0.00210369193689759, 87, 2853],\n",
       " [0.0021051876951553774, 42, 4698],\n",
       " [0.002105637860780371, 32, 4515],\n",
       " [0.002107898868763883, 92, 2394],\n",
       " [0.0021080459827248384, 44, 5964],\n",
       " [0.0021083128840763154, 36, 1496],\n",
       " [0.0021087316607320637, 79, 2400],\n",
       " [0.0021094954228036695, 99, 546],\n",
       " [0.0021095696609431435, 69, 3221],\n",
       " [0.002110107999160898, 39, 3789],\n",
       " [0.0021105168681649507, 67, 456],\n",
       " [0.0021111176857600915, 40, 4371],\n",
       " [0.0021152950156160246, 87, 701],\n",
       " [0.002116981903878155, 81, 3605],\n",
       " [0.00211894875911619, 73, 3293],\n",
       " [0.002120179091583795, 53, 6749],\n",
       " [0.0021219298647219883, 85, 6925],\n",
       " [0.0021229756791747907, 88, 4257],\n",
       " [0.0021234077150116947, 58, 1660],\n",
       " [0.0021240357338046024, 64, 282],\n",
       " [0.0021247696985236264, 54, 1282],\n",
       " [0.00212524272571147, 52, 4969],\n",
       " [0.0021254853017218375, 45, 1891],\n",
       " [0.0021270646106424807, 83, 7029],\n",
       " [0.0021276687562146266, 74, 6074],\n",
       " [0.0021289520243999243, 88, 1703],\n",
       " [0.0021295981778974185, 79, 6080],\n",
       " [0.002130609211768997, 65, 4834],\n",
       " [0.0021332966586863947, 97, 2901],\n",
       " [0.0021335205657122265, 45, 4828],\n",
       " [0.002133702299850715, 50, 1053],\n",
       " [0.0021357317865124876, 51, 4163],\n",
       " [0.002137363520882274, 64, 3126],\n",
       " [0.0021377943640495654, 37, 4142],\n",
       " [0.002138423054679912, 44, 206],\n",
       " [0.002139717893078061, 89, 4144],\n",
       " [0.002141876233287778, 63, 4742],\n",
       " [0.0021435768232219475, 92, 826],\n",
       " [0.0021447027524003764, 85, 115],\n",
       " [0.0021467305449235337, 64, 4583],\n",
       " [0.002146792477420258, 85, 4611],\n",
       " [0.002147534232370911, 50, 3187],\n",
       " [0.0021492647489840416, 51, 2264],\n",
       " [0.0021510350640800723, 89, 74],\n",
       " [0.0021522038620331863, 75, 245],\n",
       " [0.002153453550717499, 87, 4982],\n",
       " [0.0021536150900685223, 86, 1771],\n",
       " [0.0021560855242547918, 36, 1351],\n",
       " [0.0021562245731128653, 87, 4328],\n",
       " [0.0021591657885284337, 96, 4136],\n",
       " [0.002159663089309733, 34, 1062],\n",
       " [0.002161487986886303, 67, 2730],\n",
       " [0.002163434347702529, 47, 3331],\n",
       " [0.0021642750857171866, 96, 4159],\n",
       " [0.002167093094033808, 35, 3564],\n",
       " [0.0021692744625281587, 45, 3555],\n",
       " [0.0021696797347872487, 54, 7077],\n",
       " [0.0021724436841404756, 93, 2870],\n",
       " [0.0021739224704284904, 66, 742],\n",
       " [0.002174012577216803, 36, 5495],\n",
       " [0.0021742768066352666, 75, 3244],\n",
       " [0.002176866753651891, 85, 6322],\n",
       " [0.0021806187814291753, 69, 3889],\n",
       " [0.0021812734517586115, 65, 4939],\n",
       " [0.002181943674421244, 69, 1197],\n",
       " [0.0021843790871421066, 76, 4579],\n",
       " [0.0021862715924606774, 39, 4006],\n",
       " [0.002186799755758199, 53, 3947],\n",
       " [0.0021879873305003655, 96, 7024],\n",
       " [0.0021887456090689916, 70, 6374],\n",
       " [0.002189486368771273, 88, 3338],\n",
       " [0.0021903576039905073, 39, 5676],\n",
       " [0.0021906970630326903, 53, 3257],\n",
       " [0.002192309617739808, 54, 3391],\n",
       " [0.0021940432238001534, 61, 2805],\n",
       " [0.00219489246785615, 79, 4019],\n",
       " [0.0021952229493749855, 32, 734],\n",
       " [0.0021960182683262606, 62, 2600],\n",
       " [0.0021976569942723672, 93, 3227],\n",
       " [0.002198824878532967, 90, 2455],\n",
       " [0.0021993310681949507, 82, 4319],\n",
       " [0.0022017320521068957, 65, 2501],\n",
       " [0.002202780846402168, 33, 4885],\n",
       " [0.002202953349508816, 55, 5810],\n",
       " [0.0022035521459595185, 42, 435],\n",
       " [0.0022036578748194165, 74, 5872],\n",
       " [0.0022037332405158193, 59, 3817],\n",
       " [0.0022068509555013254, 49, 2100],\n",
       " [0.002206916545997803, 33, 5138],\n",
       " [0.0022089379380113025, 55, 5909],\n",
       " [0.0022090278275016845, 73, 1009],\n",
       " [0.002210625343941816, 87, 4711],\n",
       " [0.002212697254430821, 92, 1149],\n",
       " [0.0022142007547523612, 58, 4845],\n",
       " [0.0022208618285615533, 94, 4922],\n",
       " [0.002224064530828463, 61, 4455],\n",
       " [0.002225047404253801, 45, 4692],\n",
       " [0.002225237229023492, 73, 1715],\n",
       " [0.002226159285606935, 68, 591],\n",
       " [0.0022262612001768657, 37, 3863],\n",
       " [0.002233523484958779, 73, 4531],\n",
       " [0.002235184044567895, 85, 7311],\n",
       " [0.0022359616868978657, 68, 1676],\n",
       " [0.0022360741879078553, 97, 1834],\n",
       " [0.0022366632941000926, 42, 3721],\n",
       " [0.002237036919582246, 34, 291],\n",
       " [0.002241672112037394, 88, 6183],\n",
       " [0.0022419305398572705, 76, 3113],\n",
       " [0.0022426591545304008, 82, 3450],\n",
       " [0.0022445126101532484, 55, 5927],\n",
       " [0.002245302978482546, 99, 1251],\n",
       " [0.0022494017036355394, 65, 856],\n",
       " [0.0022511399581373348, 68, 3033],\n",
       " [0.0022543912474671073, 32, 3587],\n",
       " [0.0022561895137763023, 77, 6351],\n",
       " [0.002256334547531943, 98, 4365],\n",
       " [0.0022605602159049987, 63, 5389],\n",
       " [0.0022607725133688026, 75, 6175],\n",
       " [0.0022612468010018705, 91, 6201],\n",
       " [0.002261508549031129, 34, 6515],\n",
       " [0.0022619030684420827, 88, 1946],\n",
       " [0.002264535043802532, 90, 615],\n",
       " [0.002266406127856711, 69, 4216],\n",
       " [0.002266652327722761, 42, 657],\n",
       " [0.0022686403998053717, 94, 3488],\n",
       " [0.0022689484584991833, 39, 5174],\n",
       " [0.002269743115333008, 49, 2451],\n",
       " [0.0022708020620857685, 32, 3277],\n",
       " [0.0022717681833567343, 93, 5739],\n",
       " [0.002271947264121311, 97, 5899],\n",
       " [0.0022738714934336136, 69, 5204],\n",
       " [0.002276745427732549, 73, 1616],\n",
       " [0.0022775972548267054, 85, 5841],\n",
       " [0.0022776288153030628, 95, 4362],\n",
       " [0.002280512247997739, 35, 468],\n",
       " [0.0022812779856468974, 87, 936],\n",
       " [0.002283706114253487, 71, 2073],\n",
       " [0.0022839507538712123, 56, 2211],\n",
       " [0.002285175407674949, 92, 6287],\n",
       " [0.002285611637943531, 83, 2657],\n",
       " [0.002286625543097551, 69, 1600],\n",
       " [0.002286780440309037, 95, 781],\n",
       " [0.0022911367003168102, 40, 656],\n",
       " [0.0022916257478206685, 45, 2530],\n",
       " [0.0022918047658902737, 87, 2262],\n",
       " [0.002291997084532232, 32, 4174],\n",
       " [0.002293366849097513, 46, 1097],\n",
       " [0.0022946867336729906, 73, 6830],\n",
       " [0.00229600584255298, 45, 6836],\n",
       " [0.002296385848181776, 39, 3409],\n",
       " [0.00229868378482522, 36, 1089],\n",
       " [0.0022986944652469824, 73, 1082],\n",
       " ...]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors.sort(key = lambda x : x[0])\n",
    "neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330464"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(x) for x in forestMap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "tmp_FI = copy.deepcopy(FI1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "for singf,f_index,parent in neighbors:\n",
    "    a = forest[f_index].tree_.children_left[parent]\n",
    "    b = forest[f_index].tree_.children_right[parent]\n",
    "    if a ==-1 or b == -1:\n",
    "        print(singf,f_index,parent)\n",
    "    c = forest[f_index].tree_.children_left[a]\n",
    "    d = forest[f_index].tree_.children_left[b]\n",
    "    if c != -1 or d != -1:\n",
    "        print(singf,f_index,parent,c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree._tree import TREE_LEAF\n",
    "#neighbors.sort(key = lambda x : x[0])\n",
    "delete_mapa = {}\n",
    "for singf,f_index,parent in neighbors[:int(len(W) * 0.1)]:\n",
    "#for singf,f_index,parent in neighbors:\n",
    "    forest[f_index].tree_.children_left[parent] = TREE_LEAF\n",
    "    forest[f_index].tree_.children_right[parent] = TREE_LEAF\n",
    "#     if f_index not in delete_mapa.keys():\n",
    "#         delete_mapa[f_index] = [parent]\n",
    "#     else: \n",
    "#         delete_mapa[f_index] = delete_mapa[f_index] + [parent]\n",
    "\n",
    "#     #print(singf,f_index,parent)\n",
    "#     # a = forest[f_index].tree_.children_left[parent]\n",
    "#     # b = forest[f_index].tree_.children_right[parent]\n",
    "#     # if a ==-1 or b == -1:\n",
    "#     #     print(singf,f_index,parent)\n",
    "#     # c = forest[f_index].tree_.children_left[a]\n",
    "#     # d = forest[f_index].tree_.children_left[b]\n",
    "#     # if c != -1 or d != -1:\n",
    "#     #     print(singf,f_index,parent,c,d)\n",
    "#     # print(forest[f_index].tree_.children_left[parent])\n",
    "#     # print(forest[f_index].tree_.children_right[parent])\n",
    "#     # print(forest[f_index].tree_.children_left[a])\n",
    "#     # print(forest[f_index].tree_.children_left[b])\n",
    "# for key,values in delete_mapa.items():\n",
    "#     print(key,len(values))\n",
    "#     # node_indexes = list(forestMap[key].keys())\n",
    "    \n",
    "#     # for v in values:\n",
    "#     #     node_indexes.append(v)\n",
    "#     #     node_indexes.remove(v+1)\n",
    "#     #     node_indexes.remove(v+2)\n",
    "#     # node_indexes.sort()\n",
    "#     # forestMap[key] = dict(zip(node_indexes,list(range(len(node_indexes)))))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-145-30bffba361d5>:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sum(np.array(list(delete_mapa.values()))[:,1])/ 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36981.5"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(list(delete_mapa.values()))[:,1])/ 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 6, 23]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =  [1,3,4,6]\n",
    "a.append(23)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(forest[0].tree_.children_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI[:,0] = FI.getcol(0) + FI.getcol(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 2]\n",
      " [0 0 3]\n",
      " [4 5 6]]\n",
      "[[ 1  2  2]\n",
      " [ 0  3  3]\n",
      " [ 4 11  6]]\n",
      "[[ 2  2]\n",
      " [ 3  3]\n",
      " [11  6]]\n"
     ]
    }
   ],
   "source": [
    "row = np.array([0, 0, 1, 2, 2, 2])\n",
    "col = np.array([0, 2, 2, 0, 1, 2])\n",
    "data = np.array([1, 2, 3, 4, 5, 6])\n",
    "a = csr_matrix((data, (row, col)), shape=(3, 3))\n",
    "print(a.toarray())\n",
    "a[:,1] = a.getcol(1) + a.getcol(2)\n",
    "print(a.toarray())\n",
    "print(a.tolil()[:,[1,2]].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.020985986039304214"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.get_decfun_coef(feat_idx=7, label_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 369792 into shape (100,10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-948623570dc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mW1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnorms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msum_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 369792 into shape (100,10)"
     ]
    }
   ],
   "source": [
    "W1 = np.array(W).reshape(100,10)\n",
    "W1[1]\n",
    "norms = [np.linalg.norm(w) for w in W1]\n",
    "sum_norms = []\n",
    "\n",
    "for i in range(len(norms) - 1):\n",
    "    sum_norms.append(norms[i] + norms[i+1])\n",
    "sum_enumerate = list(enumerate(sum_norms))\n",
    "sum_enumerate.sort(key= lambda x : x[1])\n",
    "only10 = sum_enumerate[:int(len(sum_enumerate) * 0.1)] \n",
    "for index,_ in only10:\n",
    "    a = W1[index]\n",
    "    b = W1[index+1]\n",
    "    W1[index] = a + b\n",
    "W1 = np.delete(W1,[x[0] for x in only10],axis=0)\n",
    "\n",
    "print(W1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05131417664551044"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(W1[99])\n",
    "#np.linalg.norm(W1[98])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(W,X):\n",
    "    a = np.array([f.predict(X) for f in forest]).T\n",
    "    b = np.array([[indexing(a.astype(int),10) for a in b] for b in a])\n",
    "    predic = np.array([W @ x for x in b])\n",
    "    return predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = predict_y(W,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([[np.argmax(np.absolute(x)) for x in b] for b in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = np.array([np.argmax(np.absolute(b)) for b in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "a2 = np.array([mode(r) for r in a1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a3[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1[576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-38659276f584>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzero_one_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0merror_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzero_one_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0merror_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mzero_one_loss\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m     \"\"\"\n\u001b[1;32m--> 911\u001b[1;33m     score = accuracy_score(y_true, y_pred,\n\u001b[0m\u001b[0;32m    912\u001b[0m                            \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                            sample_weight=sample_weight)\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "error_rate = zero_one_loss(y_test, y_pred)\n",
    "error_rate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5fede5b92e480afc6e05a222ab8b607bd54a666c127ae4b3a964fbf0cbfe8314"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
